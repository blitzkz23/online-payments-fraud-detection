{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span><center><div style=\"font-family: Trebuchet MS; background-color: #1e81b0; color: #eeeee4; padding: 12px; line-height: 1;\">Training Pipeline Notebook</div></center></span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I separated the machine learning training pipeline from the EDA for cleaner approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span><center><div style=\"font-family: Trebuchet MS; background-color: #1e81b0; color: #eeeee4; padding: 12px; line-height: 1;\">Import Necessary Libraries</div></center></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration purpose\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML Model related\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report, recall_score, precision_score, f1_score, roc_auc_score, plot_roc_curve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from joblib import dump\n",
    "from joblib import load\n",
    "\n",
    "# Data balancing\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Other\n",
    "import joblib\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span><center><div style=\"font-family: Trebuchet MS; background-color: #1e81b0; color: #eeeee4; padding: 12px; line-height: 1;\">Load Dataset</div></center></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '../dataset/cleaned-fraud-payments.csv'\n",
    "payment_fraud_df = pd.read_csv(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th>diffOrig</th>\n",
       "      <th>diffDest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>181.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>181.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>181.00</td>\n",
       "      <td>21182.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362615</th>\n",
       "      <td>743</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>339682.13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>339682.13</td>\n",
       "      <td>-339682.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362616</th>\n",
       "      <td>743</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>6311409.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6311409.28</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362617</th>\n",
       "      <td>743</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>6311409.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6311409.28</td>\n",
       "      <td>-6311409.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362618</th>\n",
       "      <td>743</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>850002.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>850002.52</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6362619</th>\n",
       "      <td>743</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>850002.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>850002.52</td>\n",
       "      <td>-850002.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6362620 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         step      type      amount  isFraud  isFlaggedFraud    diffOrig  \\\n",
       "0           1   PAYMENT     9839.64        0               0     9839.64   \n",
       "1           1   PAYMENT     1864.28        0               0     1864.28   \n",
       "2           1  TRANSFER      181.00        1               0      181.00   \n",
       "3           1  CASH_OUT      181.00        1               0      181.00   \n",
       "4           1   PAYMENT    11668.14        0               0    11668.14   \n",
       "...       ...       ...         ...      ...             ...         ...   \n",
       "6362615   743  CASH_OUT   339682.13        1               0   339682.13   \n",
       "6362616   743  TRANSFER  6311409.28        1               0  6311409.28   \n",
       "6362617   743  CASH_OUT  6311409.28        1               0  6311409.28   \n",
       "6362618   743  TRANSFER   850002.52        1               0   850002.52   \n",
       "6362619   743  CASH_OUT   850002.52        1               0   850002.52   \n",
       "\n",
       "           diffDest  \n",
       "0              0.00  \n",
       "1              0.00  \n",
       "2              0.00  \n",
       "3          21182.00  \n",
       "4              0.00  \n",
       "...             ...  \n",
       "6362615  -339682.13  \n",
       "6362616        0.00  \n",
       "6362617 -6311409.27  \n",
       "6362618        0.00  \n",
       "6362619  -850002.52  \n",
       "\n",
       "[6362620 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payment_fraud_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span><center><div style=\"font-family: Trebuchet MS; background-color: #1e81b0; color: #eeeee4; padding: 12px; line-height: 1;\">Data Preprocessing</div></center></span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = payment_fraud_df.drop(columns='isFraud')\n",
    "y = payment_fraud_df['isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of sample in whole dataset: 6362620\n",
      "=========================================\n",
      "Total # of sample in train dataset: 4453834\n",
      "=========================================\n",
      "Total # of sample in test dataset: 1908786\n"
     ]
    }
   ],
   "source": [
    "# Check each sample of splitted data\n",
    "print(f'Total # of sample in whole dataset: {len(X)}')\n",
    "print('=========================================')\n",
    "print(f'Total # of sample in train dataset: {len(X_train)}')\n",
    "print('=========================================')\n",
    "print(f'Total # of sample in test dataset: {len(X_test)}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoding\n",
    "Label Encoder is used to turn categorical column into numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling with Robust Scaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our exploration phase, we concluded that the dataset are heavily-imbued with outliers, that's why we use Robust Scaler to scale it.  RobustScaler is a preprocessing technique used to scale numeric features in a dataset. It scales the features to be centered around the median value and scales the data according to the interquartile range (IQR) rather than the mean and standard deviation, which makes it robust to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numeric and categorical features\n",
    "numerical_features = payment_fraud_df.select_dtypes(exclude=object).columns.tolist()\n",
    "categorical_features = payment_fraud_df.select_dtypes(include=object).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column transformer for pipeline use later\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('encoder', encoder, categorical_features),\n",
    "    ('scaler', scaler, numerical_features)\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span><center><div style=\"font-family: Trebuchet MS; background-color: #1e81b0; color: #eeeee4; padding: 12px; line-height: 1;\">Model Building</div></center></span>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building pipeline, model selection or hyperparameter tuning first we are gonna compare all of ML algorithm to select the best base for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n",
    "models, predictions = clf.fit(X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8aa1b9473439039f34c808b0fbd903a84078e0a113d57573a8ff0e6da3c1f9c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
